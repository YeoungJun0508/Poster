이미지 백본과 얼굴 랜드마크 탐지기를 결합하여 트랜스포머 아키텍처를 구축한다.

입력이미지와 랜드마크 특성을 결합하여 퓨즈드 특성을 생성한 후 멀티헤드 자가 어텐션 레이어를 사용하여 특성들 간의 상관 관계를 캡처한다.

간단한 연결만으로는 이미지와 랜드마크 특성 간의 강한 상관 관계를 완전히 활용 못하므로 개선하기위해 만들었다.

POSTER는 크로스-퓨전 트랜스포머 인코더를 활용하여 이미지 특성과 랜드마크 특성 간의 협업을 강화

POSTER는 피라미드 구조를 도입하여 FER 작업에서 발생할 수 있는 스케일 민감성을 처리한다.


특성 협업과 피라미드 구조를 POSTER에 통합함으로써, FER의 핵심 도전 과제를 체계적으로 해결하는 통합된 프레임워크를 구축


### 특성 협업(Feature Collaboration)

POSTER는 이미지 백본에서 추출된 이미지 특성과 얼굴 랜드마크에서 추출된 특성을 협업시킨다.

### 크로스 퓨전 (Cross-Fusion)

트랜스포머 인코더에서의 역할: 크로스 퓨전은 이미지 특성과 랜드마크 특성 간의 상호작용을 강화하는 방법.

특성의 보완: 랜드마크 특성은 중요한 얼굴 지점의 세부 정보를 포함하고 있어 이를 통해 이미지 특성은 보다 정확한 표정 분류를 수행.


### 피라미드 구조

다중 스케일 특성 추출: 입력 이미지를 서로 다른 해상도 및 크기의 다양한 단계로 나누어 각각의 단계에서 특성을 추출.. 보통 "큰", "중간", "작은" 또는 "고해상도", "중간 해상도", "저해상도"와 같은 레벨로 구분됩니다.

단계별 처리: 각 단계에서 추출된 특성은 별도의 크로스-퓨전 트랜스포머 인코더에 입력.
이 과정에서 각 스케일에서의 중요한 특성과 상호작용을 모델이 학습하고 통합.

통합된 특성 표현: 각각의 크로스-퓨전 트랜스포머 인코더에서 처리된 다중 스케일 특성은 마지막 단계에서 집계.
이 과정에서 다양한 해상도와 크기에서 추출된 정보를 종합적으로 활용하여 표정 특성을 잘 파악하고 분류.


![image](https://github.com/YeoungJun0508/Poster/assets/145903037/5c5167ab-8ad7-4e0c-8970-d35f01786e8b)


POSTER에서는 크로스-퓨전 트랜스포머 인코더를 도입하여 이미지 특성과 랜드마크 특성의 협업을 강화


이미지 백본(IR50)과 얼굴 랜드마크 검출기(MobileFaceNet)를 사용하여 각각 이미지 특성 
𝑋
𝑖
𝑚
𝑔
X 
img
​
 과 랜드마크 특성 
𝑋
𝑙
𝑚
X 
lm
​
 을 추출



이 두 특성은 크로스-퓨전 방식으로 결합되어 전체적인 얼굴 특성을 향상시키는 데 기여함.





### 크로스-퓨전 트랜스포머 인코더 


![image](https://github.com/YeoungJun0508/Poster/assets/145903037/4250dd7a-86fa-4526-8cb5-e88385e2c284)


다른 소스에서 추출된 특성들을 결합하여 특정 작업에 적합하도록 설계된 트랜스포머의 변형




입력 특성 매핑:

이미지 특성 
𝑋
𝑖
𝑚
𝑔
X 
img
​
 : 이미지 백본(예: IR50)을 통해 추출된 이미지 특성.
랜드마크 특성 
𝑋
𝑙
𝑚
X 
lm
​
 : 얼굴 랜드마크 검출기(예: MobileFaceNet)를 사용하여 얻은 랜드마크 특성.



선형 변환:

각 입력 특성인 

𝑋
𝑖
𝑚
𝑔
X 
img
​
 와 
𝑋
𝑙
𝑚
X 
lm
​
 은 선형 변환을 통해 쿼리(Q), 키(K), 값(V) 행렬로 매핑됩니다.
 
𝑄
𝑖
𝑚
𝑔
=
𝑋
𝑖
𝑚
𝑔
⋅
𝑊
𝑄
1
Q 
img
​
 =X 
img
​
 ⋅W 
Q1
​
 , 
𝐾
𝑖
𝑚
𝑔
=
𝑋
𝑖
𝑚
𝑔
⋅
𝑊
𝐾
1
K 
img
​
 =X 
img
​
 ⋅W 
K1
​
 , 
𝑉
𝑖
𝑚
𝑔
=
𝑋
𝑖
𝑚
𝑔
⋅
𝑊
𝑉
1
V 
img
​
 =X 
img
​
 ⋅W 
V1
​
 
𝑄
𝑙
𝑚
=
𝑋
𝑙
𝑚
⋅
𝑊
𝑄
2
Q 
lm
​
 =X 
lm
​
 ⋅W 
Q2
​
 , 
𝐾
𝑙
𝑚
=
𝑋
𝑙
𝑚
⋅
𝑊
𝐾
2
K 
lm
​
 =X 
lm
​
 ⋅W 
K2
​
 , 
𝑉
𝑙
𝑚
=
𝑋
𝑙
𝑚
⋅
𝑊
𝑉
2
V 
lm
​
 =X 
lm
​
 ⋅W 
V2
​
 
여기서 
𝑊
𝑄
1
,
𝑊
𝑄
2
,
𝑊
𝐾
1
,
𝑊
𝐾
2
,
𝑊
𝑉
1
,
𝑊
𝑉
2
W 
Q1
​
 ,W 
Q2
​
 ,W 
K1
​
 ,W 
K2
​
 ,W 
V1
​
 ,W 
V2
​
 는 선형 변환 매개변수.


 
크로스-퓨전 연산:

크로스-퓨전 트랜스포머 인코더는 쿼리(Q) 매트릭스를 다른 특성 소스로 교환하여 각 특성의 강점을 서로에게 전달.

예를 들어, 
𝑄
𝑖
𝑚
𝑔
Q 
img
​
 는 
𝑄
𝑙
𝑚
Q 
lm
​
 으로 교환되어 이미지 특성이 랜드마크 특성의 중요한 영역을 반영할 수 있게 한다.
이 과정에서 이미지 특성은 랜드마크의 지역적인 정보를 활용하여 보다 정확한 특성을 추출하게 되고, 랜드마크 특성은 이미지의 전역적인 맥락을 이해하게된다.


통합된 특성은 감정 레이블을 예측하는 다층 퍼셉트론 (MLP) 헤드로 전달되어 최종 출력인 감정 레이블을 얻는다.


주요 네트워크 구조 -  ResNet, EfficientNet 

224x224 픽셀 크기의 이미지


#### 손실함수
CircleLoss, SupConLoss, LabelSmoothingCrossEntropy, SoftTargetCrossEntropy 등의 손실 함수들이 정의

#### 전처리
train_transform, val_transform 등의 데이터 전처리 방법이 정의


#### 이미지 입력

데이터는 train_loader, val_loader 등을 통해 미니배치 형태로 입력
#### 전처리

train_transform, val_transform 함수를 사용하여 이미지 데이터를 텐서로 변환하고, 필요에 따라 데이터 증강(augmentation)을 수행
#### 모델 통과

데이터는 ResNet 모델을 통과하여 특징(feature)으로 변환, ResNet은 여러 층의 합성곱(convolutional) 및 풀링(pooling) 층을 통해 이미지의 공간적 특징을 추출
#### 특징 추출

최종적으로 추출된 특징은 CircleLoss, SupConLoss 등의 손실 함수를 계산하는 데 사용, 이 손실 함수들은 모델의 출력과 정답 레이블 간의 차이를 계산하여 학습 과정에서 최적됩니다.
